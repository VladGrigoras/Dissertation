{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e8ee07f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pylab\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import pandas as pd\n",
    "from scipy.optimize import curve_fit\n",
    "from scipy.optimize import minimize\n",
    "from scipy.optimize import differential_evolution\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "import string\n",
    "from scipy.special import logsumexp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d3e9403",
   "metadata": {},
   "source": [
    "# Network structure\n",
    "Variables that define the structure of the network model in the following terms:\n",
    "- dimensions of the encoded space, \n",
    "- number of neurons, \n",
    "- receptive fields (RF) centres."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f34d6bb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Tactile area\n",
    "# Tactile area dimensions (cm)\n",
    "xt = 20\n",
    "yt = 10\n",
    "\n",
    "# Tactile neurons (count)\n",
    "Mt = 40 #Mt = 40 in Magosso2010b\n",
    "Nt = 20 #Nt = 20 in Magosso2010b\n",
    "\n",
    "# Tactile RF centres (cm)\n",
    "xrft = np.arange(1, Mt + 1) * 0.5 - 0.25\n",
    "yrft = np.arange(1, Nt + 1) * 0.5 - 0.25\n",
    "\n",
    "## Auditory area\n",
    "# Auditory area dimensions (cm)\n",
    "xa = 200\n",
    "ya = 30\n",
    "\n",
    "# Auditory neurons (count)\n",
    "Ma = 20\n",
    "Na = 3\n",
    "\n",
    "# Auditory RF centres (cm)\n",
    "xrfa = np.arange(1, Ma+1) * 10 - 5\n",
    "yrfa = np.arange(1, Na+1) * 10 - 15\n",
    "\n",
    "## Visual area\n",
    "# Visual area dimensions (cm)\n",
    "xv = 100 \n",
    "yv = 15\n",
    "\n",
    "xtool = 85 #or 95\n",
    "\n",
    "# Visual neurons (count)\n",
    "Mv = 100\n",
    "Nv = 15\n",
    "\n",
    "#Visual RF centres (cm)\n",
    "xrfv = np.arange(1, Mv + 1) - 0.5    #As per Magosso2010b\n",
    "yrfv = np.arange(1, Nv + 1) - 3 #As per Magosso2010b\n",
    "\n",
    "dx = 0.2\n",
    "dy = 0.2 "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2c81fe76",
   "metadata": {},
   "source": [
    "# Network fixed parameters\n",
    "Variables that define the values of the parameters that remain fixed in our study. These parameters are related to: \n",
    "- the RF of the unisensory neurons,\n",
    "- the activation functions of both unisensory and multisensory neurons, \n",
    "- the visual and tactile stimuli that is administered during the experiment simulation and training simulation.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "da5549bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Model fixed parameters for simulation/experiment setting\n",
    "#Question for Renato - why is ya_0 = 5, rather than 15?\n",
    "\n",
    "## Unisensory receptive fields\n",
    "phit_0 = 1       #Magosso2010b\n",
    "sigmat_phi = 0.5 #Magosso2010b\n",
    "\n",
    "phia_0 = 1       #Serino2015\n",
    "sigmaa_phi = 10  #Serino2015\n",
    "\n",
    "phiv_0 = 1       #Magosso2010b\n",
    "sigmav_phi = 1   #Magosso2010b\n",
    "\n",
    "## Neuronal activity\n",
    "\n",
    "# Tactile neurons\n",
    "fmin_t = -0.12   \n",
    "fmax_t = 1       \n",
    "qc_t = 19.43\n",
    "r_t = 0.34\n",
    "\n",
    "# Auditory neurons\n",
    "fmin_a = -0.12   \n",
    "fmax_a = 1       \n",
    "qc_a = 19.43\n",
    "r_a = 0.34\n",
    "\n",
    "#Visual neurons\n",
    "fmin_v = -0.12\n",
    "fmax_v = 1\n",
    "qc_v = 19.43\n",
    "r_v = 0.34\n",
    "\n",
    "# Multisensory neuron\n",
    "fmin_m = 0\n",
    "fmax_m = 1\n",
    "qc_m = 12\n",
    "r_m = 0.6\n",
    "\n",
    "tau = 20\n",
    "\n",
    "## External stimuli - Experimental Setting\n",
    "# Tactile stimuli\n",
    "It_0_exp = 2.5\n",
    "sigt_exp = 0.3\n",
    "yt_0_exp = 5 # cm\n",
    "xt_0_exp = 10 # cm\n",
    "\n",
    "# Auditory stimuli\n",
    "Ia_0_exp = 3.6\n",
    "siga_exp = 0.3\n",
    "ya_0_exp = 5 # cm\n",
    "xa_0_exp = 100 # cm\n",
    "\n",
    "# Visual Stimuli:\n",
    "#Participant is blindfolded during experimental setting - no visual stimulus\n",
    "\n",
    "#Gaussian noise\n",
    "\n",
    "signoise_t = 0\n",
    "signoise_a = 0\n",
    "\n",
    "stdnoise = 1\n",
    "\n",
    "## External stimuli - Training Setting\n",
    "# Tactile stimuli\n",
    "It_0_tr = 0.56\n",
    "sigtx_tr = 0.75\n",
    "sigty_tr = 1.25\n",
    "\n",
    "# Auditory stimuli\n",
    "Ia_0_tr =  0.0125 \n",
    "sigax_tr = 3.75\n",
    "sigay_tr = 6\n",
    "\n",
    "# Visual Stimuli:\n",
    "Iv_0_tr = 0.121\n",
    "sigvx_tr = 3.75\n",
    "sigvy_tr = 6\n",
    "\n",
    "#Gaussian noise - training auditory and visual stimuli are much more noisy than before\n",
    "\n",
    "signoiset_t = 0.01\n",
    "signoiset_a = 0.2\n",
    "signoiset_v = 0.3\n",
    "\n",
    "stdnoise = 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2eddf83",
   "metadata": {},
   "source": [
    "# External stimuli functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c5a548bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "## External stimulus - experiment run\n",
    "\n",
    "def stimspace_exp(s, x0, y0):\n",
    "\n",
    "    \"\"\"Compute the stimulus intensity for the unimodal space s (t/a) for a stimulus centered around x0 and y0. This stimulus is specifically related to\n",
    "    the experimental setting, which exlusively utilises audio-tactile information.\n",
    "    \n",
    "    Input:\n",
    "        s  (char): region of stimulation (tactile/auditory)\n",
    "        x0 (int):  center point on the x axis of the stimulus\n",
    "        y0 (int):  center point on the y axis of the stimulus\n",
    "\n",
    "    Output:\n",
    "        v (2D.np.array): matrix of stimulus intensity for the entire unimodal space \n",
    "    \"\"\"\n",
    "\n",
    "    if s == \"t\": \n",
    "        a = np.reshape(np.repeat(np.arange(0, xt + dx, dx), int(yt/dy + 1)), (int(xt/dx + 1), int(yt/dy + 1)))\n",
    "        b = np.reshape(np.tile(np.arange(0, yt + dx, dx), (int(xt/dx + 1))), (int(xt/dx + 1), int(yt/dy + 1)))\n",
    "\n",
    "        v = (np.ones((int(xt/dx + 1), int(yt/dy + 1))) * It_0_exp + np.ones((int(xt/dx + 1), int(yt/dy + 1))) * signoise_t * np.random.randn()) * np.exp(- (np.square(np.ones((int(xt/dx + 1), int(yt/dy + 1))) * x0 - a) + np.square(np.ones((int(xt/dx + 1), int(yt/dy + 1))) * y0 - b)) /  (2 * np.square(sigt_exp)))\n",
    "    else:\n",
    "        a = np.reshape(np.repeat(np.arange(0, xa + dx, dx), int(ya/dy + 1)), (int(xa/dx + 1), int(ya/dy + 1)))\n",
    "        b = np.reshape(np.tile(np.arange(0, ya + dx, dx), (int(xa/dx + 1))), (int(xa/dx + 1), int(ya/dy + 1)))\n",
    "\n",
    "        v = (np.ones((int(xa/dx + 1), int(ya/dy + 1))) * Ia_0_exp + np.ones((int(xa/dx + 1), int(ya/dy + 1))) * signoise_a * np.random.randn()) * np.exp(- (np.square(np.ones((int(xa/dx + 1), int(ya/dy + 1))) * x0 - a) + np.square(np.ones((int(xa/dx + 1), int(ya/dy + 1))) * y0 - b)) /  (2 * np.square(siga_exp)))\n",
    "  \n",
    "    return v\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdaf6275",
   "metadata": {},
   "source": [
    "# Receptive fields functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d2e10bf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#RF formula\n",
    "\n",
    "def phi(s, x, y):\n",
    "    \"\"\"Obtain the RF of the unimodality s (t/a/v) for a given set of spatial coordinates.\n",
    "\n",
    "    Input:\n",
    "        s (char): unimodality (t/a/v)\n",
    "        x (int): Spatial coordinate in the x-axis (cm). \n",
    "        y (int): Spatial coordinate in the y-axis (cm).\n",
    "        \n",
    "    Output:\n",
    "        phi (2D.np.array): RF of the unimodality for the given spatial coordinates.\n",
    "    \"\"\" \n",
    "    \n",
    "    # Build the RF matrix\n",
    "    if(s == \"t\"):\n",
    "        phi = np.zeros((Mt,Nt))\n",
    "\n",
    "        # Compute the RF for the tactile space on the given spatial coordinates\n",
    "        for i in range(Mt):\n",
    "            for j in range(Nt):\n",
    "                phi[i,j] = phit_0 * np.exp(-((np.square(xrft[i]-x) + np.square(yrft[j]-y)) / (2*np.square(sigmat_phi))))\n",
    "\n",
    "    elif(s == \"a\"):\n",
    "        phi = np.zeros((Ma,Na))\n",
    "\n",
    "        # Compute the RF for the auditory space on the given spacial coordinates\n",
    "        for i in range(Ma):\n",
    "            for j in range(Na):\n",
    "                phi[i,j] = phia_0 * np.exp(-((np.square(xrfa[i]-x) + np.square(yrfa[j]-y)) / (2*np.square(sigmaa_phi))))\n",
    "\n",
    "    else:\n",
    "        phi = np.zeros((Mv,Nv))\n",
    "    \n",
    "        # Compute the RF for the visual space on the given spatial coordinates\n",
    "        for i in range(Mv):\n",
    "            for j in range(Nv):\n",
    "                phi[i][j] = phiv_0 * np.exp(-((np.square(xrfv[i]-x) + np.square(yrfv[j]-y)) / (2*np.square(sigmav_phi))))\n",
    "    return phi   \n",
    "\n",
    "\n",
    "\n",
    "def PhiRF(s):\n",
    "\n",
    "    \"\"\"Compute the RF of the unisensory areas for the discreteised spatial coordinates in the auditory and tactile spaces. \n",
    "    I run this once and then save the RFs as they do not change.\n",
    "    \n",
    "    Input:\n",
    "        s (char): the unimodal region of interest (t/a/v)\n",
    "    \n",
    "    Output:\n",
    "        Phi (4D np.array): RF of the area for the discretised spatial coordinates in the space.\n",
    "    \"\"\" \n",
    "    \n",
    "    # Calculate the discretised spatial coordinates\n",
    "    if s == \"t\":\n",
    "        xl = xt\n",
    "        yn = yt\n",
    "        Phi = np.zeros((Mt,Nt,int(xt/dx + 1), int(yt/dy + 1)))  \n",
    "    \n",
    "    elif(s == \"a\"):\n",
    "        xl = xa\n",
    "        yn = ya\n",
    "        Phi = np.zeros((Ma,Na,int(xa/dx + 1), int(ya/dy + 1)))    \n",
    "\n",
    "    else:\n",
    "        xl = xv\n",
    "        yn = yv\n",
    "        Phi = np.zeros((Mv,Nv,int(xv/dx + 1), int(yv/dy + 1)))  \n",
    "\n",
    "    for k in range(int(xl/dx + 1)):\n",
    "        for l in range(int(yn/dy + 1)):\n",
    "            Phi[:,:,k,l] = phi(s, k * dx, l * dy)\n",
    "\n",
    "    return Phi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "65f236ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Uncomment if you do no thave access to these numpy objects already\n",
    "\n",
    "#Phit = PhiRF(\"t\")\n",
    "#Phia = PhiRF(\"a\")\n",
    "#Phiv = PhiRF(\"v\")\n",
    "\n",
    "#np.save(\"Phit.npy\", Phit)\n",
    "#np.save(\"Phia.npy\", Phia)\n",
    "#np.save(\"Phiv.npy\", Phiv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6dc54bbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "Phit = np.load(\"Phit.npy\")\n",
    "Phia = np.load(\"Phia.npy\")\n",
    "Phiv = np.load(\"Phiv.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69577fe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def PHI_expa(s, x0, y0):\n",
    "    \"\"\"This function computes the external input to the unimodal area \"s\" based on a stimulus centered around x0 and y0\n",
    "    Input:\n",
    "        s (char): unimodality (a/t)\n",
    "        x0 (int): center of the external stimulus on the x axis\n",
    "        y0 (int): center of the external stimulus on the y axis \n",
    "    \n",
    "    Assumed Inputs:\n",
    "        Phit (4D.np.array): a matrix of each tactile neuron's receptive field \n",
    "        Phia (4D.np.array): a matrix of each auditory neuron's receptive field\n",
    "    \"\"\"\n",
    "\n",
    "    PHI = np.sum(np.multiply(Phia, stimspace_exp(s, x0, y0)), (3, 2))\n",
    "\n",
    "    return PHI\n",
    "\n",
    "def PHI_expt(s, x0, y0):\n",
    "    \"\"\"This function computes the external input to the unimodal area \"s\" based on a stimulus centered around x0 and y0\n",
    "    Input:\n",
    "        s (char): unimodality (a/t)\n",
    "        x0 (int): center of the external stimulus on the x axis\n",
    "        y0 (int): center of the external stimulus on the y axis \n",
    "    \n",
    "    Assumed Inputs:\n",
    "        Phit (4D.np.array): a matrix of each tactile neuron's receptive field \n",
    "        Phia (4D.np.array): a matrix of each auditory neuron's receptive field\n",
    "    \"\"\"\n",
    "\n",
    "    PHI = np.sum(np.multiply(Phit, stimspace_exp(s, x0, y0)), (3, 2))\n",
    "\n",
    "    return PHI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12582936",
   "metadata": {},
   "source": [
    "# Synapses functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "07c39aec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Lw(Lex_t, Lin_t, sigmaex_t, sigmain_t, Lex_a, Lin_a, sigmaex_a, sigmain_a, Lex_v, Lin_v, sigmaex_v, sigmain_v):\n",
    "    \"\"\"Compute the matrix of lateral connections (akin to a Mexican Hat Function). Still have not decided on the border effects.\n",
    "\n",
    "    Input:\n",
    "        Lex_t (int): the excitatory amplitude for the tactile lateral synapses\n",
    "        sigmaex_t (int): the excitatory spread for the tactile lateral synapses\n",
    "        Lin_t (int): the inhibitory amplitude for the tactile synapses\n",
    "        sigmain_t (int): the inhibitory spread for the tactile synapses      \n",
    "\n",
    "        Lex_a (int): the excitatory amplitude for the auditory lateral synapses\n",
    "        sigmaex_a (int): the excitatory spread for the auditory lateral synapses\n",
    "        Lin_a (int): the inhibitory amplitude for the auditory synapses\n",
    "        sigmain_a (int): the inhibitory spread for the auditory synapses   \n",
    "\n",
    "        Lex_v (int): the excitatory amplitude for the visual lateral synapses\n",
    "        sigmaex_v (int): the excitatory spread for the visual lateral synapses\n",
    "        Lin_v (int): the inhibitory amplitude for the visual synapses\n",
    "        sigmain_v (int): the inhibitory spread for the visual synapses   \n",
    "\n",
    "    Output:\n",
    "        Lt (4D.np.array): the map of tactile lateral connections for each neuron (each ij position has a matrix detailing its connections with all neurons)\n",
    "        La (4D.np.array): the map of auditory lateral connections for each neuron (each ij position has a matrix detailing its connections with all neurons)\n",
    "        Lv (4D.np.array): the map of visual lateral connections for each neuron (each ij position has a matrix detailing its connections with all neurons)\n",
    "    \"\"\"\n",
    "    #Tactile recurrent connections\n",
    "\n",
    "    # calculate Dx and Dy using matrix operations\n",
    "\n",
    "    Lt = Lex_t * np.exp(-(np.square(xrft[:,None,None,None] - xrft[None,None,:,None]) + np.square(yrft[None,:,None,None] - yrft[None,None,None,:])) / (2 * sigmaex_t**2)) - Lin_t * np.exp(- (np.square(xrft[:,None,None,None] - xrft[None,None,:,None]) + np.square(yrft[None,:,None,None] - yrft[None,None,None,:])) / (2 * sigmain_t**2))\n",
    "    La = Lex_a * np.exp(-(np.square(xrfa[:,None,None,None] - xrfa[None,None,:,None]) + np.square(yrfa[None,:,None,None] - yrfa[None,None,None,:])) / (2 * sigmaex_a**2)) - Lin_a * np.exp(- (np.square(xrfa[:,None,None,None] - xrfa[None,None,:,None]) + np.square(yrfa[None,:,None,None] - yrfa[None,None,None,:])) / (2 * sigmain_a**2))\n",
    "    Lv = Lex_v * np.exp(-(np.square(xrfv[:,None,None,None] - xrfv[None,None,:,None]) + np.square(yrfv[None,:,None,None] - yrfv[None,None,None,:])) / (2 * sigmaex_v**2)) - Lin_v * np.exp(- (np.square(xrfv[:,None,None,None] - xrfv[None,None,:,None]) + np.square(yrfv[None,:,None,None] - yrfv[None,None,None,:])) / (2 * sigmain_v**2))\n",
    "    \n",
    "    Lt = np.where(Lt == np.max(Lt), 0, Lt)\n",
    "    La = np.where(La == np.max(La), 0, La)\n",
    "    Lv = np.where(Lv == np.max(Lv), 0, Lv)\n",
    "\n",
    "    return Lt, La, Lv\n",
    "\n",
    "def FwFb(Wt_0, Wa_0, Wv_0, Bt_0, Ba_0, Bv_0, k1, k2, lim, alpha):\n",
    "    \"\"\"Feedforward and feedback synaptic weights of the unisensory neurons.\n",
    "\n",
    "    Args:\n",
    "        Wt_0 (int): Maximum value of the feedforward synapses in the tactile area.\n",
    "        Wa_0 (int): Maximum value of the feedforward synapses in the auditory area.\n",
    "        Wv_0 (int): Maximum value of the feedforward synapses in the visual area.\n",
    "\n",
    "        Bt_0 (int): Maximum value of the feedback synapses in the tactile area. \n",
    "        Ba_0 (int): Maximum value of the feedback synapses in the auditory area.\n",
    "        Bv_0 (int): Maximum value of the feedback synapses in the visual area.\n",
    "           \n",
    "        k1 (int): Fast decay rate.\n",
    "        k2 (int): Slow decay rate.\n",
    "        lim (int): Boundary of the space on and near the hand.\n",
    "        alpha (int): Relative amplitude of each exponential.\n",
    "        \n",
    "    Returns:\n",
    "        Wt (2D np.array): Feedforward synaptic weights in the tactile area.\n",
    "        Wa (2D np.array): Feedforward synaptic weights in the auditory area.\n",
    "        Wv (2D np.array): Feedforward synaptic weights in the visual area.\n",
    "        \n",
    "        Bt (2D np.array): Feedback synaptic weights in the tactile area.\n",
    "        Ba (2D np.array): Feedback synaptic weights in the auditory area.\n",
    "        Bv (2D np.array): Feedback synaptic weights in the visual area.\n",
    "    \"\"\" \n",
    "    \n",
    "    # Build the feedforward and feedback synapses matrices\n",
    "    \n",
    "    Bt = np.ones((Mt, Nt)) * Bt_0 #tactile feedback synapses identical\n",
    "    Wt = np.ones((Mt, Nt)) * Wt_0 #tactile feedback synapses identical\n",
    "\n",
    "    Ba = np.zeros((Ma, Na))\n",
    "    Wa = np.zeros((Ma, Na))\n",
    "\n",
    "    Bv = np.zeros((Mv, Nv))\n",
    "    Wv = np.zeros((Mv, Nv))\n",
    "    \n",
    "    # Compute the feedforward and feedback synapses in the auditory area\n",
    "    for i in range(Ma):\n",
    "        for j in range(Na):\n",
    "\n",
    "            if (xrfa[i]<lim): D = 0\n",
    "            else: D = np.linalg.norm(xrfa[i] - lim)     \n",
    "\n",
    "            Ba[i,j] = alpha * Ba_0 * np.exp(- D/k1) + (1-alpha) * Ba_0 * np.exp(- D/k2)\n",
    "            Wa[i,j] = alpha * Wa_0 * np.exp(- D/k1) + (1-alpha) * Wa_0 * np.exp(- D/k2)\n",
    "\n",
    "    # Compute the feedforward and feedback synapses in the visual area\n",
    "    for i in range(Mv):\n",
    "        for j in range(Nv):\n",
    "\n",
    "            if (xrfv[i]<lim): D = 0\n",
    "            else: D = np.linalg.norm(xrfv[i] - lim)            \n",
    "            \n",
    "            Bv[i,j] = alpha * Bv_0 * np.exp(- D/k1) + (1-alpha) * Bv_0 * np.exp(- D/k2)\n",
    "            Wv[i,j] = alpha * Wv_0 * np.exp(- D/k1) + (1-alpha) * Wv_0 * np.exp(- D/k2)\n",
    "       \n",
    "    return Wt,Wa,Wv,Bt,Ba,Bv"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "69af2ca0",
   "metadata": {},
   "source": [
    "# Cross Modal Synapses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8edded6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def crossmodal(at, sigat, vt, sigvt, av, sigav):\n",
    "\n",
    "    \"\"\" Create the crossmodal synapses across all unimodal regions. These synapses act similarly to the lateral connections. \n",
    "    They mimic a mexican hat function, having an excitatory peak, followed by  inhibitory surroundings. \n",
    "    \n",
    "    Input:\n",
    "    at (int): strength of the excitatory Gaussian for the audiotactile connections\n",
    "    sigat (int): spread of the excitatory Gaussian for the audiotactile connections\n",
    "\n",
    "    av (int): strength of the excitatory Gaussian for the audiovisual connections\n",
    "    sigav (int): spread of the excitatory Gaussian for the audiovisual connections\n",
    "    \n",
    "    vt (int): strength of the excitatory Gaussian for the visuotactile connections\n",
    "    sigvt (int): spread of the excitatory Gaussian for the visuootactile connections\n",
    "\n",
    "    Output:\n",
    "\n",
    "    Wat (4D.np.array): a MxN matrix of auditory neurons, each containing their connections to the MxN tactile neurons (i,j,:,:); or alternatively\n",
    "    a Mx N matrix of tactile neurons, each containing their connections to the MxN auditory neurons (:,:,i,j) \n",
    "    Wav (4D.np.array): a MxN matrix of visual neurons, each containing their connections to the MxN auditory neurons (i,j,:,:); or alternatively\n",
    "    a Mx N matrix of auditory neurons, each containing their connections to the MxN visual neurons (:,:,i,j)     \n",
    "    Wvt (4D.np.array): a MxN matrix of visual neurons, each containing their connections to the MxN tactile neurons (i,j,:,:); or alternatively\n",
    "    a Mx N matrix of tactile neurons, each containing their connections to the MxN visual neurons (:,:,i,j) \n",
    "    \"\"\"\n",
    "    \n",
    "    dx = xrfa.reshape(Ma, 1, 1, 1) - xrft.reshape(1, 1, Mt, 1)\n",
    "    dy = yrfa.reshape(1, Na, 1, 1) - yrft.reshape(1, 1, 1, Nt)\n",
    "    Wat = at * np.exp(- ((np.square(dx) + np.square(dy))/ (2  * np.square(sigat))))\n",
    "    \n",
    "    dx = xrfv.reshape(Mv, 1, 1, 1) - xrft.reshape(1, 1, Mt, 1)\n",
    "    dy = yrfv.reshape(1, Nv, 1, 1) - yrft.reshape(1, 1, 1, Nt)\n",
    "    Wvt = vt * np.exp(- ((np.square(dx) + np.square(dy))/ (2  * np.square(sigvt))))\n",
    "    \n",
    "    dx = xrfa.reshape(Ma, 1, 1, 1) - xrfv.reshape(1, 1, Mv, 1)\n",
    "    dy = yrfa.reshape(1, Na, 1, 1) - yrfv.reshape(1, 1, 1, Nv)\n",
    "    Wav = av * np.exp(- ((np.square(dx) + np.square(dy))/ (2  * np.square(sigav))))\n",
    "    \n",
    "    return Wat, Wvt, Wav\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f8e43c6",
   "metadata": {},
   "source": [
    "# Neural activity functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def neural(qt, qa, qv, qm, Lt, La, Lv, zt, za, zv, Wat, Wvt, Wav, zm, Bt, Ba, Bv):\n",
    "    \"\"\"Compute the rates (z) as the sigmoid of the dynamic state variable\n",
    "\n",
    "    Input:\n",
    "        s (char): unimodality (a/t/v)\n",
    "        q (2D.np.array): state variable\n",
    "\n",
    "    Assumed Inputs:\n",
    "        fmin_t (int): lower boundary of the tactile sigmoid function\n",
    "        fmax_t (int): upper boundary of the tactile sigmoid function\n",
    "        qc_t (int): central point of the tactile sigmoid function\n",
    "        r_t (int): slope of the tactile sigmoid curve at the central point qc_t\n",
    "\n",
    "        fmin_a (int): lower boundary of the auditory sigmoid function\n",
    "        fmax_a (int): upper boundary of the auditory sigmoid function\n",
    "        qc_a (int): central point of the auditory sigmoid function\n",
    "        r_a (int): slope of the auditory sigmoid curve at the central point qc_a      \n",
    "    \n",
    "        fmin_m (int): lower boundary of the multisensory sigmoid function\n",
    "        fmax_m (int): upper boundary of the multisensory sigmoid function\n",
    "        qc_m (int): central point of the multisensory sigmoid function\n",
    "        r_m (int): slope of the multisensory sigmoid curve at the central point qc_m\n",
    "\n",
    "    Output:\n",
    "        psi (2D.np.array) the rates for the unimodality s\n",
    "    \"\"\"\n",
    "\n",
    "    #Cross-Modal Inputs\n",
    "    \n",
    "    psit = (np.ones((Mt, Nt)) * fmin_t + fmax_t * np.exp((qt - np.ones((Mt, Nt)) * qc_t) * r_t)) / (np.ones((Mt, Nt)) + np.exp((qt - np.ones((Mt, Nt)) * qc_t) * r_t))\n",
    "    psia = (np.ones((Ma, Na)) * fmin_a + fmax_a * np.exp((qa - np.ones((Ma, Na)) * qc_a) * r_a)) / (np.ones((Ma, Na)) + np.exp((qa - np.ones((Ma, Na)) * qc_a) * r_a))\n",
    "    psiv = (np.ones((Mv, Nv)) * fmin_v + fmax_v * np.exp((qv - np.ones((Mv, Nv)) * qc_v) * r_v)) / (np.ones((Mv, Nv)) + np.exp((qv - np.ones((Mv, Nv)) * qc_v) * r_v))\n",
    "    \n",
    "    psim = (fmin_m + fmax_m * np.exp((qm - qc_m) * r_m)) / (1 + np.exp((qm - qc_m) * r_m))\n",
    "\n",
    "    LT = np.einsum('hkij, ij -> hk', Lt, zt)\n",
    "    LA = np.einsum('hkij, ij -> hk', La, za)\n",
    "    LV = np.einsum('hkij, ij -> hk', Lv, zv)\n",
    "    AT = np.einsum('ijhk, ij -> hk', Wat, za)\n",
    "    AV = np.einsum('ijhk, ij -> hk', Wav, za)\n",
    "    VT = np.einsum('ijhk, ij -> hk', Wvt, zv)\n",
    "    VA = np.einsum('hkij, ij -> hk', Wav, zv)\n",
    "    TA = np.einsum('hkij, ij -> hk', Wat, zt)\n",
    "    TV = np.einsum('hkij, ij -> hk', Wvt, zt)\n",
    "\n",
    "    BT = np.multiply(Bt, zm)\n",
    "    BA = np.multiply(Ba, zm)\n",
    "    BV = np.multiply(Bv, zm)\n",
    "\n",
    "    return psit, psia, psiv, psim, LT, LA, LV, AT, AV, TA, TV, VT, VA, BT, BA, BV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "196ac961",
   "metadata": {},
   "source": [
    "# Evolutionary pruning mechanism"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a327f1a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Built after Paredes et al., 2021\n",
    "\n",
    "def prun(WM, pr):\n",
    "    \"\"\"Computes synaptic pruning according to a fixed threshold rule. \n",
    "    \n",
    "    Inout:\n",
    "        WM (2D np.array/4D.np.array): Feedforward/Cross-Modal synaptic weight matrix.\n",
    "        pr (number): Pruning threshold.\n",
    "        \n",
    "    Output:\n",
    "        newM (2D np.array/4D.np.array): Pruned weight matrix.\n",
    "    \"\"\" \n",
    "    \n",
    "    # Copy the original matrix\n",
    "    newM = np.copy(WM)\n",
    "    \n",
    "    # Prune synaptic weights below the given threshold\n",
    "    newM[newM < pr] = 0\n",
    "    \n",
    "    return newM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f545eaf",
   "metadata": {},
   "source": [
    "# Audio-tactile experiment function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a5fd519c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def experiment(ts, T, dist, ya, Lt, La, Lv, Wt, Wa, Wv, Bt, Ba, Bv, Wat, Wvt, Wav, FWpr, CMpr):\n",
    "    \"\"\" Run a PPS-assessment simulation using the following parameters\n",
    "    Input:\n",
    "        ts (int): the discretising timestep of the Euler integration\n",
    "        T (int): the total simulation runtime\n",
    "        tau (int): time constant \n",
    "        dist (1D.np.array): vector of distance \n",
    "        ya (int): location on the y-axis of the auditory stimulus\n",
    "\n",
    "        Lt (4D.np.array): A matrix of shape (MxN) in which every ij position is another matrix of shape (MxN), \n",
    "                          in which every hk position details the lateral connectivity of ij with hk for the tactile region\n",
    "        La (4D.np.array): A matrix of shape (MxN) in which every ij position is another matrix of shape (MxN), \n",
    "                          in which every hk position details the lateral connectivity of ij with hk for the auditory region\n",
    "        Lv (4D.np.array): A matrix of shape (MxN) in which every ij position is another matrix of shape (MxN), \n",
    "                          in which every hk position details the lateral connectivity of ij with hk for the visual region\n",
    "                          \n",
    "        Wt (2D np.array): Feedforward synaptic weights in the tactile area.\n",
    "        Wa (2D np.array): Feedforward synaptic weights in the auditory area.\n",
    "        Wv (2D np.array): Feedforward synaptic weights in the visual area.\n",
    "        \n",
    "        Bt (2D np.array): Feedback synaptic weights in the tactile area.\n",
    "        Ba (2D np.array): Feedback synaptic weights in the auditory area.\n",
    "        Bv (2D np.array): Feedback synaptic weights in the visual area        \n",
    "\n",
    "        Wat (4D.np.array): a MxN matrix of auditory neurons, each containing their connections to the MxN tactile neurons (i,j,:,:); or alternatively\n",
    "        a Mx N matrix of tactile neurons, each containing their connections to the MxN auditory neurons (:,:,i,j) \n",
    "        Wav (4D.np.array): a MxN matrix of visual neurons, each containing their connections to the MxN auditory neurons (i,j,:,:); or alternatively\n",
    "        a Mx N matrix of auditory neurons, each containing their connections to the MxN visual neurons (:,:,i,j)     \n",
    "        Wvt (4D.np.array): a MxN matrix of visual neurons, each containing their connections to the MxN tactile neurons (i,j,:,:); or alternatively\n",
    "        a Mx N matrix of tactile neurons, each containing their connections to the MxN visual neurons (:,:,i,j) \n",
    "\n",
    "    Output:\n",
    "        zt (4D.np.array): the activation values for the tactile region for each timestep given each auditory vertical distance\n",
    "        za (4D.np.array): the activation values for the auditory region for each timestep given each auditory vertical distance\n",
    "        zv (4D.np.array): the activation values for the visual region for each timestep given each auditory vertical distance\n",
    "        zm (2D.np.array): the activation values for the multisensory neuron for each timestep given each auditory vertical distance\n",
    "        RTs (1D.np.array): the reaction times for each given distance\n",
    "    \"\"\"\n",
    "    n = int(T/ts) #number of iterations\n",
    "    tt = ts/tau\n",
    "    #Pruning of Connections\n",
    "    \n",
    "    Wa = prun(Wa, FWpr)\n",
    "    Wv = prun(Wv, FWpr)\n",
    "\n",
    "    Wat = prun(Wat, CMpr)\n",
    "    Wvt = prun(Wvt, CMpr)\n",
    "    Wav = prun(Wav, CMpr)\n",
    "\n",
    "    ti = PHI_expt(\"t\", xt/2, yt/2) #tactile stimuluis\n",
    "\n",
    "    qt = np.zeros((Mt,Nt,len(dist), n)) \n",
    "    ut = np.zeros((Mt,Nt,len(dist), n))\n",
    "    zt = np.zeros((Mt,Nt,len(dist), n))\n",
    "\n",
    "    qa = np.zeros((Ma,Na,len(dist), n))\n",
    "    ua = np.zeros((Ma,Na,len(dist), n))\n",
    "    za = np.zeros((Ma,Na,len(dist), n))\n",
    "\n",
    "    qv = np.zeros((Mv,Nv,len(dist), n))\n",
    "    uv = np.zeros((Mv,Nv,len(dist), n))\n",
    "    zv = np.zeros((Mv,Nv,len(dist), n))\n",
    "\n",
    "    qm = np.zeros((len(dist), n))\n",
    "    um = np.zeros((len(dist), n))\n",
    "    zm = np.zeros((len(dist), n))\n",
    "\n",
    "    rt = np.zeros((len(dist), n))\n",
    "    RTs = np.zeros(len(dist))\n",
    "\n",
    "    for i in range(len(dist)):\n",
    "\n",
    "        ai = PHI_expa(\"a\", dist[i], ya) #auditory stimulus\n",
    "        for j in range(1, n):\n",
    "\n",
    "            psit, psia, psiv, psim, LT, LA, LV, AT, AV, TA, TV, VT, VA, BT, BA, BV = neural(qt[:,:,i,j-1], qa[:,:,i,j-1], qv[:,:,i,j-1], qm[i,j-1], Lt, La, Lv, zt[:,:,i,j-1], za[:,:,i,j-1], zv[:,:,i,j-1], Wat, Wvt, Wav, zm[i, j-1], Bt, Ba, Bv)\n",
    "\n",
    "            ut[:,:,i, j] = ti + LT + BT + AT + VT\n",
    "            qt[:,:,i, j] = qt[:,:,i,j - 1] + tt * (- qt[:,:,i,j - 1] + ut[:,:,i,j - 1])\n",
    "            zt[:,:,i, j] = np.maximum(psit, 0) #heaviside function\n",
    "\n",
    "            ua[:,:,i, j] = ai + LA + BA + TA + VA\n",
    "            qa[:,:,i, j] = qa[:,:,i,j - 1] + tt * (- qa[:,:,i,j - 1] + ua[:,:,i,j - 1])\n",
    "            za[:,:,i, j] = np.maximum(psia, 0) #heaviside function\n",
    "\n",
    "            uv[:,:,i, j] = LV + BV + TV + AV\n",
    "            qv[:,:,i, j] = qv[:,:,i,j - 1] + tt * (- qv[:,:,i,j - 1] + uv[:,:,i,j - 1])\n",
    "            zv[:,:,i, j] = np.maximum(psiv, 0) #heaviside function\n",
    "\n",
    "            um[i, j] = np.einsum('ij, ij -> ', Wt, zt[:,:,i, j-1]) + np.einsum('ij, ij -> ', Wa, za[:, :, i, j - 1]) + np.einsum('ij, ij -> ', Wv, zv[:, :, i, j - 1])\n",
    "            qm[i, j] = qm[i,j - 1] + tt * (- qm[i,j - 1] + um[i,j - 1])\n",
    "            zm[i, j] = np.maximum(psim, 0) #heaviside function\n",
    "\n",
    "            rt[i, j] = np.any(zt[:,:,i,j - 1] > (0.9))\n",
    "\n",
    "        #Compute the RT for this distance\n",
    "\n",
    "        RTs[i] = np.argmax(rt[i, :]) * ts * 3 + 60\n",
    "\n",
    "\n",
    "    return zt, za, zm, zv, RTs"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "eca1d15c",
   "metadata": {},
   "source": [
    "# Training Input Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7c4c4fbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stim_tr(s, x, y, x0, y0):\n",
    "    \"\"\" Compute the training stimuli for one point for modality s (a/t/v)\n",
    "    \n",
    "    Input:\n",
    "    s (char): the modality (auditory/tactile/visual)\n",
    "    x (int): x coordinate\n",
    "    y (int): y coordinate\n",
    "\n",
    "    Output:\n",
    "\n",
    "    I (int): the stimulus intensity \n",
    "    \"\"\"\n",
    "\n",
    "    if s == \"t\":\n",
    "        #if ((3 < y < 7) and ((5 < x < 10))): I = It_0_tr\n",
    "        #else: I = 0\n",
    "        I = (It_0_tr + signoiset_t * np.random.randn()) * np.exp(- ((np.square(x0 - x)) / (2 * np.square(sigtx_tr))) - ((np.square(y0 - y)) / (2 * np.square(sigty_tr))))\n",
    "\n",
    "    elif s == \"a\":\n",
    "        I = (Ia_0_tr + signoiset_a * np.random.randn()) * np.exp(- ((np.square(x0 - x)) / (2 * np.square(sigax_tr))) - ((np.square(y0 - y)) / (2 * np.square(sigay_tr))))\n",
    "\n",
    "    else:\n",
    "        I = (Iv_0_tr + signoiset_v * np.random.randn()) * np.exp(- ((np.square(x0 - x)) / (2 * np.square(sigvx_tr))) - ((np.square(y0 - y)) / (2 * np.square(sigvy_tr))))\n",
    "\n",
    "    return I\n",
    "\n",
    "def stimspace_tr(s, x0, y0):\n",
    "\n",
    "    \"\"\"Compute the stimulus intensity for the unimodal space s (t/a) for a stimulus centered around x0 and y0\n",
    "    \n",
    "    Input:\n",
    "        s  (char): region of stimulation (tactile/auditory)\n",
    "        x0 (int): vertical center of stimulus\n",
    "        y0 (int): horizontal center of stimulus\n",
    "        \n",
    "    Output:\n",
    "        v (2D.np.array): matrix of stimulus intensity for the entire unimodal space \n",
    "    \"\"\"\n",
    "\n",
    "    if s == \"t\": \n",
    "\n",
    "        v = np.zeros((int(xt/dx + 1), int(yt/dy + 1)))\n",
    "        for x in range(int(xt/dx + 1)):\n",
    "            for y in range(int(yt/dy + 1)):\n",
    "                v[x,y] = stim_tr(\"t\", x * dx, y * dy, x0, y0)\n",
    "                \n",
    "    elif s == \"a\":\n",
    "\n",
    "        v = np.zeros((int(xa/dx + 1), int(ya/dy + 1)))\n",
    "        for x in range(int(xa/dy + 1)):\n",
    "            for y in range(int(ya/dy + 1)):\n",
    "                v[x,y] = stim_tr(\"a\", x * dx, y * dy, x0, y0)\n",
    "    else:\n",
    "        \n",
    "        v = np.zeros((int(xv/dx + 1), int(yv/dy + 1)))\n",
    "        for x in range(int(xv/dy + 1)):\n",
    "            for y in range(int(yv/dy + 1)):\n",
    "                v[x,y] = stim_tr(\"v\", x * dx, y * dy, x0, y0)      \n",
    "\n",
    "    return v\n",
    "\n",
    "def PHI_tr(s, x0, y0):\n",
    "    \"\"\"This function computes the external input to the unimodal area \"s\" based on a stimulus centered around x0 and y0\n",
    "    Input:\n",
    "        s (char): unimodality (a/t)\n",
    "        x0 (int): center of the external stimulus on the x axis\n",
    "        y0 (int): center of the external stimulus on the y axis \n",
    "    \n",
    "    Assumed Inputs:\n",
    "        Phit (4D.np.array): a matrix of each tactile neuron's receptive field \n",
    "        Phia (4D.np.array): a matrix of each auditory neuron's receptive field\n",
    "    \"\"\"\n",
    "\n",
    "    if s == \"t\": Phi = Phit\n",
    "    elif s == \"a\": Phi = Phia\n",
    "    else: Phi = Phiv\n",
    "\n",
    "    PHI = np.multiply(Phi, stimspace_tr(s, x0, y0))\n",
    "    \n",
    "    PHI = np.sum(PHI,axis=3)\n",
    "    PHI = np.sum(PHI,axis=2)\n",
    "\n",
    "    return PHI"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "840a200b",
   "metadata": {},
   "source": [
    "# Auditory - Visual - Tactile Training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a374a96c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#100 total movements, so 100 network presentations?\n",
    "\n",
    "def FWTraining(m, T, ts, Lt, La, Lv, Wt, Wa, Wv, Bt, Ba, Bv, Wat, Wvt, Wav, FWpr, rho_0, Wmax_a, Wmax_v, k_v, k_a, theta):\n",
    "\n",
    "    \"\"\"Train the feedforward auditory and visual weights \n",
    "\n",
    "    Input:\n",
    "\n",
    "        stcount (int): number of presentations\n",
    "        T (int): simulation steps (ms)\n",
    "        ts (int): timestep\n",
    "\n",
    "        Lt (4D.np.array): tactile lateral connections\n",
    "        La (4D.np.array): auditory lateral connections\n",
    "        Lv (4D.np.array): visual lateral connections\n",
    "        Wt (2D.np.array): feedforward tactile connections\n",
    "        Wa (2D.np.array): feedforward auditory connections\n",
    "        Wv (2D.np.array): feedforward visual connections\n",
    "        Bt (2D.np.array): feedback tactile connections\n",
    "        Ba (2D.np.array): feedback auditory connections\n",
    "        Bv (2D.np.array): feedback visual connections\n",
    "\n",
    "        rho_0 (int): reinforcing factor\n",
    "        Wmax_a (int): maximum value for auditory weights\n",
    "        Wmax_v (int): maximum value for visual weights\n",
    "        k_a (int): auditory forgetting factor \n",
    "        k_v (int): visual forgetting factor\n",
    "        theta (int): multisensory neuron activation thrseshold \n",
    "\n",
    "    Output:\n",
    "        Wa_tr (4D.np.array): feedfoward auditory connections for the snychronous condition\n",
    "        Wv_tr (4D.np.array): feedfoward visual connections for the snychronous condition\n",
    "    \"\"\"\n",
    "    #Initialise Weights // initially, they start off with the predefined feedforward weights // AS - Asynchronous, S - Synchronous\n",
    "\n",
    "    n = int(T/ts)\n",
    "    tt = ts/tau\n",
    "\n",
    "    Wa = prun(Wa, FWpr)\n",
    "    Wv = prun(Wv, FWpr)\n",
    "\n",
    "    Wa_tr = np.zeros((Ma, Na, m, n))\n",
    "    Wv_tr = np.zeros((Mv, Nv, m, n))\n",
    "\n",
    "    Wa_tr[:,:,0, 0] = Wa\n",
    "    Wv_tr[:,:,0, 0] = Wv\n",
    "\n",
    "    qt = np.zeros((Mt, Nt, m, n)) \n",
    "    ut = np.zeros((Mt, Nt, m, n))\n",
    "    zt = np.zeros((Mt, Nt, m, n))\n",
    "\n",
    "    qa = np.zeros((Ma, Na, m, n))\n",
    "    ua = np.zeros((Ma, Na, m, n))\n",
    "    za = np.zeros((Ma, Na, m, n))\n",
    "\n",
    "    qv = np.zeros((Mv, Nv, m, n))\n",
    "    uv = np.zeros((Mv, Nv, m, n))\n",
    "    zv = np.zeros((Mv, Nv, m, n))\n",
    "\n",
    "    qm = np.zeros((m, n))\n",
    "    um = np.zeros((m, n))\n",
    "    zm = np.zeros((m, n))\n",
    "\n",
    "    for i in range(m):\n",
    "\n",
    "        ti = PHI_tr(\"t\", 10, 5) #tactile stimulus\n",
    "        ai = PHI_tr(\"a\", 85, 5) #auditory stimulus\n",
    "        vi = PHI_tr(\"v\", 85, 5) #visual stimulus    \n",
    "\n",
    "        #Intialise weights, either to the predefined ones, or to the ones from the previous simulation\n",
    "        if i != 0:\n",
    "\n",
    "            Wa_tr[:,:,i,0] = Wa_tr[:, :, i-1, -1]\n",
    "            Wv_tr[:,:,i,0] = Wv_tr[:, :, i-1, -1]\n",
    "\n",
    "        for j in range(1, n):\n",
    "\n",
    "            psit, psia, psiv, psim, LT, LA, LV, AT, AV, TA, TV, VT, VA, BT, BA, BV = neural(qt[:,:,i,j-1], qa[:,:,i,j-1], qv[:,:,i,j-1], qm[i,j-1], Lt, La, Lv, zt[:,:,i,j-1], za[:,:,i,j-1], zv[:,:,i,j-1], Wat, Wvt, Wav, zm[i, j-1], Bt, Ba, Bv)\n",
    "\n",
    "            ut[:,:,i, j] = ti + LT + BT + AT + VT\n",
    "            qt[:,:,i, j] = qt[:,:,i,j - 1] + tt * (- qt[:,:,i,j - 1] + ut[:,:,i,j - 1])\n",
    "            zt[:,:,i, j] = np.maximum(psit, 0) #heaviside function\n",
    "\n",
    "            ua[:,:,i,j] = ai + LA + BA + TA + VA\n",
    "            qa[:,:,i,j] = qa[:,:,i,j - 1] + tt * (- qa[:,:,i,j - 1] + ua[:,:,i,j - 1])\n",
    "            za[:,:,i,j] = np.maximum(psia, 0) #heaviside function\n",
    "\n",
    "            uv[:,:,i,j] = vi + LV + BV + AV + TV\n",
    "            qv[:,:,i,j] = qv[:,:,i,j - 1] + tt * (- qv[:,:,i,j - 1] + uv[:,:,i,j - 1])\n",
    "            zv[:,:,i,j] = np.maximum(psiv, 0) #heaviside function\n",
    "\n",
    "            qm[i, j] = qm[i,j - 1] + tt * (- qm[i,j - 1] + um[i,j - 1])\n",
    "            um[i, j] = np.einsum('ij, ij -> ', Wt, zt[:,:,i, j-1]) + np.einsum('ij, ij -> ', Wa_tr[:,:,i,j-1], za[:, :, i, j - 1]) + np.einsum('ij, ij -> ', Wv_tr[:,:,i,j-1], zv[:, :, i, j - 1])\n",
    "            zm[i, j] = np.maximum(psim, 0) #heaviside function\n",
    "            \n",
    "            #Auditory Feedforward Training\n",
    "            dWa = (rho_0 * (Wmax_a - Wa_tr[:,:, i, j - 1])) * za[:,:,i, j - 1] * np.maximum((zm[i,j-1] - theta), 0) - k_a * np.maximum((zm[i,j-1] - theta), 0) * (Wa_tr[:,:, i, j - 1] - Wa_tr[:,:, 0, 0]) \n",
    "            Wa_tr[:,:,i,j] = Wa_tr[:,:,i,j - 1] + dWa \n",
    "\n",
    "            #Visual Feedforward Training\n",
    "            dWv = (rho_0 * (Wmax_v - Wv_tr[:,:, i, j - 1])) * zv[:,:,i, j - 1] * np.maximum((zm[i,j-1] - theta), 0) - k_v * np.maximum((zm[i,j-1] - theta), 0) * (Wv_tr[:,:, i, j - 1] - Wv_tr[:,:, 0, 0]) \n",
    "            Wv_tr[:,:,i,j] = Wv_tr[:,:,i,j - 1] + dWv \n",
    "\n",
    "            #Tactile Training\n",
    "            #dW_t = (rho_0 * (Wmax_t - WS_t[:,:, i, j - 1])) * zt[:,:,i, j - 1] * (zm[i,j-1] - theta) * np.heaviside((zm[i,j-1] - theta), 0) - k_t * (zm[i,j-1] - theta) * np.heaviside((zm[i,j-1] - theta), 0) *(WS_t[:,:, i, j - 1] - WS_t[:,:, i, 0]) \n",
    "            #WS_t[:,:,i,j] = WS_t[:,:,i,j - 1] + dW_t \n",
    "\n",
    "\n",
    "    return Wa_tr, Wv_tr, zm, zv, za, zt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68c950d1",
   "metadata": {},
   "source": [
    "# Sigmoid fitting functions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "084f4536",
   "metadata": {},
   "outputs": [],
   "source": [
    "def RTsig(distances, cp, slope):\n",
    "    \"\"\"Compute the sigmoidal function\n",
    "    Input:\n",
    "        disances (1D.np.array): vector of distances\n",
    "        cp (int): central point of the curve\n",
    "        slope (int): slope of the curve\n",
    "    Output:\n",
    "        sig (1D.np.array): the appropriate y-values for distances as x-values\n",
    "    \"\"\"\n",
    "    global ymin\n",
    "    global ymax\n",
    "    \n",
    "    sig = (ymin + ymax * np.exp((distances - cp) / slope)) / (1 + np.exp((distances - cp) / slope))\n",
    "\n",
    "    return sig\n",
    "\n",
    "def fitting(distances, RTs):\n",
    "    \"\"\"Fit the sigmoidal curve to get the cp and slope\n",
    "\n",
    "    Input:\n",
    "        distances (1D.np.array): vector of distances\n",
    "        RTs (1D.np.array): vector of reaction times\n",
    "        \n",
    "    Output:\n",
    "        cp (int): central point of the sigmoid\n",
    "        slope (int): slope of the sigmoid\n",
    "    \"\"\"\n",
    "    \n",
    "    global ymin\n",
    "    global ymax\n",
    "\n",
    "    # Defines starting points and boundaries for the fitting\n",
    "    k_0 = (ymax - ymin)/(distances[-1] - distances[0])\n",
    "\n",
    "    initial_slope = (ymax - ymin)/(4 * k_0)\n",
    "    middle_distance = np.max(distances) / 2\n",
    "    \n",
    "    init_guess = [middle_distance, initial_slope]\n",
    "    boundaries = ([0,float('-inf')],[float('inf'),float('inf')])\n",
    "    \n",
    "    # Fits the data\n",
    "    popt, pcov = curve_fit(RTsig, xdata = distances, ydata = RTs, p0 = init_guess, method='trf', ftol=1e-8, xtol=1e-8, maxfev=10000, bounds=boundaries)\n",
    "    sigpar = np.asarray(popt)\n",
    "    \n",
    "    cp = sigpar[0]\n",
    "    slope = sigpar[1]\n",
    "    \n",
    "    return cp, slope"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6e721ae0",
   "metadata": {},
   "source": [
    "# Spearman-Karber Fitting"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "da41177a",
   "metadata": {},
   "source": [
    "### Monotonization Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "944af8af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def monotonize(fi, nTrials):\n",
    "\n",
    "    fiMono = np.copy(fi)\n",
    "\n",
    "    while (not np.all(np.diff(fiMono) >= 0)): #while non monotonic\n",
    "        i = 0\n",
    "        while i < len(fiMono) - 1:\n",
    "\n",
    "            if(fiMono[i] <= fiMono[i+1]): i+=1\n",
    "            \n",
    "            else:\n",
    "                k = 0\n",
    "                while True:\n",
    "\n",
    "                    tempfi = np.sum(fiMono[i:i + k + 1] * nTrials[i: i + k + 1]) / np.sum(nTrials[i:i + k + 1])\n",
    "                    if i + k  > len(fiMono): break\n",
    "                    elif fiMono[i + k] > tempfi: break\n",
    "                    else: k+=1\n",
    "\n",
    "                fiMono[i:i + k + 1] = np.ones(k + 1) * tempfi \n",
    "                i = i + k + 1\n",
    "\n",
    "    return fiMono\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "91a3ac0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fise(fi):\n",
    "    fi = (fi - np.min(fi)) / (np.max(fi) - np.min(fi))\n",
    "    return fi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b31d0297",
   "metadata": {},
   "outputs": [],
   "source": [
    "def SK(fi, dist, nTrials):\n",
    "    \n",
    "    DLc = 0.6745; #75th percentile of standard normal\n",
    "    s = 500\n",
    "\n",
    "    fis = fise(fi) #turn into probs\n",
    "    fim = monotonize(fis, nTrials)\n",
    "    fi = np.append(0, fim)\n",
    "    fi = np.append(fi, 1)\n",
    "    fi = np.diff(fi)\n",
    "\n",
    "    distsq = np.square(dist)\n",
    "    distcube = np.power(dist, 3)\n",
    "\n",
    "    PSE = 1/2 * np.sum(fi * np.diff(distsq) / np.diff(dist))\n",
    "    M = 1/3 * np.sum(fi * np.diff(distcube) / np.diff(dist))\n",
    "    sigSK = np.sqrt(M - PSE**2)\n",
    "    DL = sigSK  * DLc\n",
    "    CE = PSE - s\n",
    "\n",
    "    return PSE, M, sigSK, DL, CE, fim, fis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2884763c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#1359 PSE pre, 504 DL pre play around\n",
    "#fi = [283.467, 283.761, 303.932, 325.895, 329.403]\n",
    "#\n",
    "#s_dist= [3200, 2700, 2200, 1500, 800, 300, -200]\n",
    "#a_dist = [126, 111, 96, 75, 54, 39, 24] \n",
    "#SK(fi, a_dist, [1,1,1,1,1])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "aa3a3dc5",
   "metadata": {},
   "source": [
    "# Behavioural Parameters From Ferroni et al., 2022 and Di Cosmo et al., 2018"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6b45ec75",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ferroni et al., 2022\n",
    "#Sigmoidal Parameters\n",
    "\n",
    "##Pre-Training\n",
    "###Healthy Controls\n",
    "fprHCCP = 120-1.377*30 \n",
    "fprHCS = 1/0.11\n",
    "###Schizophrenia\n",
    "fprSCZCP = 120-1.666 * 30\n",
    "fprSCZS = 1/0.075\n",
    "\n",
    "##Post Training\n",
    "###Healthy Controls\n",
    "fpostHCCP = 120-1.028*30 \n",
    "fpostHCS = 1/0.18\n",
    "###Schizophrenia\n",
    "fpostSCZCP = 120-1.361*30\n",
    "fpostSCZS = 1/0.061\n",
    "\n",
    "\n",
    "#Spearman-Kaerber Parameters\n",
    "\n",
    "##Pre-Training\n",
    "###Healthy Controls\n",
    "fprHCPSE = 120 - 1.359 * 30\n",
    "fprHCDL = ... #504\n",
    "###Schizophrenia\n",
    "fprSCZPSE = 120 - 1.504*30\n",
    "fprSCZDL = ... #696\n",
    "\n",
    "##Post Training\n",
    "###Healthy Controls\n",
    "fpostHCPSE = 120 - 1.254 * 30 \n",
    "fpostHCDL = ... #540\n",
    "###Schizophrenia\n",
    "fpostSCZPSE = 120 - 1.405 * 30\n",
    "fpostSCZDL = ...#613\n",
    "\n",
    "#Di Cosmo et al., 2018\n",
    "\n",
    "dcSCZCP = 120 - 1.654 * 30 \n",
    "dcSCZS = 1 / 0.23"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ad30262e",
   "metadata": {},
   "outputs": [],
   "source": [
    "fpreHCRTSig = [279.747, 277.283, 301.396, 326, 331]\n",
    "import numpy as np\n",
    "fpostHCRTSig = [334.900769230769, 304.051538461538, 283.203846153846, 277.339230769231, 277.027692307692][::-1]\n",
    "\n",
    "fpreSRTSig = [402.582380952381, 409.355714285714, 391.851904761905, 375.072380952381, 366.409523809524][::-1]\n",
    "fpostSRTSig = [425.620952380952, 404.887142857143, 378.611428571428, 368.370952380952, 384.501904761905][::-1]\n",
    "\n",
    "fpreHCRTSK = [283, 329, 337, 304, 284][::-1]\n",
    "fpreHCRTSK = (fpreHCRTSK - np.min(fpreHCRTSK)) / (np.max(fpreHCRTSK) - np.min(fpreHCRTSK))\n",
    "fpreSRTSK = [380.642229577875, 397.821818801943, 412.798365471543, 394.017373770684, 391.223527385707][::-1]\n",
    "fpreSRTSK = (fpreSRTSK - np.min(fpreSRTSK)) / (np.max(fpreSRTSK) - np.min(fpreSRTSK))\n",
    "\n",
    "\n",
    "fpostHCRTSK = [280, 336, 313, 291, 280][::-1]\n",
    "fpostHCRTSK = (fpostHCRTSK - np.min(fpostHCRTSK)) / (np.max(fpostHCRTSK) - np.min(fpostHCRTSK))\n",
    "fpostSRTSK = [389.654637856702, 424.157148212331, 401.931595742975, 384.72284079883, 383.285761190903][::-1]\n",
    "fpostSRTSK = (fpostSRTSK - np.min(fpostSRTSK)) / (np.max(fpostSRTSK) - np.min(fpostSRTSK))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
